"""ç–²åŠ³åº¦æ¨¡å‹åç«¯

ä½¿ç”¨emotion_fatigue_inferä¸­çš„ç–²åŠ³åº¦æ¨ç†æ¨¡å‹
"""

import base64
import io
import logging
import sys
from pathlib import Path
from typing import Any, Dict, List
import time

# æ·»åŠ baseè·¯å¾„å’Œemotion_fatigue_inferè·¯å¾„
base_path = Path(__file__).parent.parent / "base"
emotion_fatigue_path = Path(__file__).parent.parent / "emotion_fatigue_infer"
fatigue_path = emotion_fatigue_path / "fatigue"

sys.path.insert(0, str(base_path))
sys.path.insert(0, str(emotion_fatigue_path))
sys.path.insert(0, str(fatigue_path))  # æ·»åŠ fatigueç›®å½•,ä»¥ä¾¿å¯¼å…¥facewap

from base_backend import BaseModelBackend

try:
    import torch
    import numpy as np
    from PIL import Image
    from fatigue.infer_multimodal import (
        FatigueFaceOnlyCNN,
        extract_eye_features_from_samples,
        extract_face_features_from_frames
    )
except ImportError as e:
    print("é”™è¯¯: ç¼ºå°‘ä¾èµ–åº“")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    print("è¯·å®‰è£…: pip install torch numpy pillow")
    sys.exit(1)


class FatigueBackend(BaseModelBackend):
    """ç–²åŠ³åº¦æ¨¡å‹åç«¯å®ç°
    
    åŠŸèƒ½:
    - å¤„ç†RGBå›¾åƒã€æ·±åº¦å›¾åƒå’Œçœ¼åŠ¨æ•°æ®
    - è¾“å‡ºç–²åŠ³åº¦åˆ†æ•° (0-100)
    """
    
    async def initialize_model(self) -> None:
        """åŠ è½½ç–²åŠ³åº¦æ¨¡å‹"""
        self.logger.info("æ­£åœ¨åŠ è½½ç–²åŠ³åº¦æ¨¡å‹...")
        
        # ç¡®å®šæ¨¡å‹è·¯å¾„
        model_dir = Path(__file__).parent.parent / "emotion_fatigue_infer" / "fatigue"
        self.model_path = model_dir / "fatigue_best_model.pt"
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        # è®¾ç½®è®¾å¤‡
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        self.model = FatigueFaceOnlyCNN().to(self.device)
        self.model.load_state_dict(torch.load(str(self.model_path), map_location=self.device))
        self.model.eval()
        
        self.logger.info("âœ… ç–²åŠ³åº¦æ¨¡å‹åŠ è½½å®Œæˆ")
    
    async def process_inference(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç–²åŠ³åº¦æ¨ç†
        
        Args:
            data: è¾“å…¥æ•°æ®,åŒ…å«:
                - rgb_frames: RGBå›¾åƒåˆ—è¡¨ (base64ç¼–ç )
                - depth_frames: æ·±åº¦å›¾åƒåˆ—è¡¨ (base64ç¼–ç )
                - eyetrack_samples: çœ¼åŠ¨æ•°æ®åˆ—è¡¨ (8ç»´ç‰¹å¾åˆ—è¡¨)
                - elapsed_time: é‡‡é›†æ—¶é•¿(ç§’)
        
        Returns:
            æ¨ç†ç»“æœ:
                - fatigue_score: ç–²åŠ³åº¦åˆ†æ•° (0-100)
                - prediction_class: é¢„æµ‹ç±»åˆ« (0æˆ–1)
                - elapsed_time: é‡‡é›†æ—¶é•¿
        """
        start_time = time.time()
        
        rgb_b64_list = data.get("rgb_frames", [])
        depth_b64_list = data.get("depth_frames", [])
        eyetrack_samples = data.get("eyetrack_samples", [])
        elapsed = data.get("elapsed_time", 0.0)
        
        # æ‰“å°è¾“å…¥ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ æ¥æ”¶åˆ°æ¨ç†è¯·æ±‚")
        print(f"{'='*60}")
        print(f"  RGBå¸§æ•°: {len(rgb_b64_list)}")
        print(f"  æ·±åº¦å¸§æ•°: {len(depth_b64_list)}")
        print(f"  çœ¼åŠ¨æ ·æœ¬æ•°: {len(eyetrack_samples)}")
        print(f"  é‡‡é›†æ—¶é•¿: {elapsed:.2f}ç§’")
        
        if not rgb_b64_list or not depth_b64_list:
            # è¿”å›é»˜è®¤åˆ†æ•°
            print(f"âš ï¸  æ•°æ®ä¸è¶³,è¿”å›é»˜è®¤å€¼")
            print(f"{'='*60}\n")
            return {
                "fatigue_score": 0.0,
                "prediction_class": 0,
                "elapsed_time": elapsed,
                "message": "æ•°æ®ä¸è¶³,è¿”å›é»˜è®¤å€¼"
            }
        
        # 1. è§£ç RGBå’Œæ·±åº¦å›¾åƒ
        rgb_frames = []
        depth_frames = []
        
        try:
            print(f"ğŸ“¸ è§£ç å›¾åƒå¸§...")
            for rgb_b64 in rgb_b64_list:
                rgb_bytes = base64.b64decode(rgb_b64)
                rgb_image = Image.open(io.BytesIO(rgb_bytes)).convert("RGB")
                rgb_array = np.array(rgb_image)
                rgb_frames.append(rgb_array)
            
            for depth_b64 in depth_b64_list:
                depth_bytes = base64.b64decode(depth_b64)
                depth_image = Image.open(io.BytesIO(depth_bytes)).convert("L")
                depth_array = np.array(depth_image)
                depth_frames.append(depth_array)
            print(f"  âœ“ è§£ç å®Œæˆ: RGB={len(rgb_frames)}å¸§, Depth={len(depth_frames)}å¸§")
        except Exception as e:
            self.logger.error(f"å›¾åƒè§£ç å¤±è´¥: {e}")
            print(f"âŒ å›¾åƒè§£ç å¤±è´¥: {e}")
            print(f"{'='*60}\n")
            raise ValueError(f"å›¾åƒè§£ç å¤±è´¥: {e}")
        
        # 2. æå–ç‰¹å¾
        try:
            frames = min(len(rgb_frames), len(depth_frames))
            print(f"ğŸ” æå–ç‰¹å¾...")
            print(f"  ä½¿ç”¨å¸§æ•°: {frames}")
            
            # æå–é¢éƒ¨ç‰¹å¾
            face_feat = extract_face_features_from_frames(
                rgb_frames, 
                depth_frames, 
                frames=frames
            ).to(self.device)  # [1, 42, frames]
            print(f"  âœ“ é¢éƒ¨ç‰¹å¾: {face_feat.shape}")
            
            # æå–çœ¼åŠ¨ç‰¹å¾
            eye_feat = extract_eye_features_from_samples(eyetrack_samples).to(self.device)  # [1, 8, T]
            print(f"  âœ“ çœ¼åŠ¨ç‰¹å¾: {eye_feat.shape}")
            
        except Exception as e:
            self.logger.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
            print(f"{'='*60}\n")
            raise ValueError(f"ç‰¹å¾æå–å¤±è´¥: {e}")
        
        # 3. æ¨¡å‹æ¨ç†
        try:
            print(f"ğŸ§  æ¨¡å‹æ¨ç†ä¸­...")
            print(f"  è¾“å…¥å½¢çŠ¶: eye_feat={eye_feat.shape}, face_feat={face_feat.shape}")
            
            with torch.no_grad():
                output = self.model(eye_feat, face_feat)  # [1, num_classes] - å·²ç»æ˜¯æ¦‚ç‡(softmaxå)
                print(f"  æ¨¡å‹åŸå§‹è¾“å‡º: {output}")
                print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
                
                probs = output.cpu().numpy()[0]  # [num_classes] - ç›´æ¥ä½¿ç”¨,ä¸å†softmax
                num_classes = output.shape[1]
                
                # åˆ†æ•°åŠ æƒæ‹Ÿåˆ: sum_i(prob_i * (i * 100 / (num_classes-1)))
                scores = np.linspace(0, 100, num_classes)
                score = float(np.dot(probs, scores))
                pred = int(np.argmax(probs))
                
            print(f"  âœ“ æ¨ç†å®Œæˆ")
            print(f"  ç±»åˆ«æ¦‚ç‡: {[f'{p:.3f}' for p in probs]}")
            print(f"  åˆ†æ•°æƒé‡: {scores}")
            print(f"  åŠ æƒè®¡ç®—: {' + '.join([f'{p:.3f}*{s:.1f}' for p, s in zip(probs, scores)])}")
                
        except Exception as e:
            self.logger.error(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
            print(f"âŒ æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
            print(f"{'='*60}\n")
            raise ValueError(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        
        inference_time = time.time() - start_time
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š æ¨ç†ç»“æœ:")
        print(f"  ç–²åŠ³åº¦åˆ†æ•°: {round(score, 2)}/100")
        print(f"  é¢„æµ‹ç±»åˆ«: {pred}")
        print(f"  æ¨ç†è€—æ—¶: {inference_time*1000:.2f}ms")
        print(f"{'='*60}\n")
        
        # è®°å½•æ¨ç†æ—¥å¿—
        self.logger.info(
            f"ç–²åŠ³åº¦æ¨ç†å®Œæˆ: åˆ†æ•°={round(score, 2)}, ç±»åˆ«={pred}, "
            f"è€—æ—¶={inference_time*1000:.0f}ms, "
            f"RGBå¸§æ•°={len(rgb_frames)}, æ·±åº¦å¸§æ•°={len(depth_frames)}, çœ¼åŠ¨æ ·æœ¬æ•°={len(eyetrack_samples)}"
        )
        
        result = {
            "fatigue_score": round(score, 2),
            "prediction_class": pred,
            "elapsed_time": round(elapsed, 2),
            "inference_time_ms": round(inference_time * 1000, 2),
            "num_rgb_frames": len(rgb_frames),
            "num_depth_frames": len(depth_frames),
            "num_eyetrack_samples": len(eyetrack_samples)
        }
        
        self.logger.debug(
            f"æ¨ç†å®Œæˆ: ç–²åŠ³åº¦åˆ†æ•°={result['fatigue_score']}, "
            f"é¢„æµ‹ç±»åˆ«={result['prediction_class']}, "
            f"æ¨ç†è€—æ—¶={result['inference_time_ms']}ms"
        )
        
        return result
    
    async def cleanup(self) -> None:
        """æ¸…ç†æ¨¡å‹èµ„æº"""
        self.logger.info("æ­£åœ¨æ¸…ç†ç–²åŠ³åº¦æ¨¡å‹èµ„æº...")
        
        # é‡Šæ”¾æ¨¡å‹
        self.model = None
        
        # æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
    log_dir = Path(__file__).parent.parent.parent / "logs" / "model"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "fatigue_backend.log"
    
    # åˆ›å»ºæ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    root_logger.addHandler(file_handler)
    
    logging.info(f"ğŸ“ æ—¥å¿—ä¿å­˜åˆ°: {log_file}")
    
    # æ¨¡å‹åç«¯é…ç½®
    config = {
        "model_type": "fatigue",
        "host": "127.0.0.1",
        "port": 8767  # ä½¿ç”¨ä¸åŒç«¯å£,é¿å…ä¸multimodalåç«¯å†²çª
    }
    
    # åˆ›å»ºå¹¶è¿è¡Œåç«¯
    backend = FatigueBackend(config)
    
    print("\n" + "=" * 70)
    print("ç–²åŠ³åº¦æ¨¡å‹åç«¯")
    print("=" * 70)
    print(f"ç›‘å¬åœ°å€: ws://{config['host']}:{config['port']}")
    print(f"æ¨¡å‹ç±»å‹: {config['model_type']}")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 70 + "\n")
    
    backend.run()


if __name__ == "__main__":
    main()
