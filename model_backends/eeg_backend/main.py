"""EEGè„‘è´Ÿè·æ¨¡å‹åç«¯

ä½¿ç”¨brain_loadä¸­çš„è„‘è´Ÿè·æ¨ç†æ¨¡å‹
å¤„ç†åŒé€šé“EEGä¿¡å·,è¾“å‡ºè„‘è´Ÿè·åˆ†æ•°
"""

import base64
import io
import logging
import sys
import time
import numpy as np
from pathlib import Path
from typing import Any, Dict, List
import tempfile
import os

# æ·»åŠ baseè·¯å¾„å’Œbrain_loadè·¯å¾„
base_path = Path(__file__).parent.parent / "base"
brain_load_path = Path(__file__).parent / "brain_load"

sys.path.insert(0, str(base_path))
sys.path.insert(0, str(brain_load_path))

from base_backend import BaseModelBackend

try:
    import joblib
    from eeg_utils import (
        FS, preprocess_eeg, segment_windows, 
        extract_features_batch, read_eeg_txt_two_channels
    )
except ImportError as e:
    print("é”™è¯¯: ç¼ºå°‘ä¾èµ–åº“")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    print("è¯·å®‰è£…: pip install joblib numpy scipy pandas")
    sys.exit(1)


class EEGBackend(BaseModelBackend):
    """EEGè„‘è´Ÿè·æ¨¡å‹åç«¯å®ç°
    
    åŠŸèƒ½:
    - å¤„ç†åŒé€šé“EEGä¿¡å· (Fp1, Fp2)
    - æå–æ—¶é¢‘åŸŸç‰¹å¾
    - è¾“å‡ºè„‘è´Ÿè·åˆ†æ•° (0-100)
    """
    
    # æ¨¡å‹å‚æ•°
    WIN_SEC = 2.0      # çª—å£é•¿åº¦(ç§’)
    STEP_SEC = 1.0     # æ»‘åŠ¨æ­¥é•¿(ç§’)
    EMA_ALPHA = 0.7    # æŒ‡æ•°ç§»åŠ¨å¹³å‡ç³»æ•°
    TH_UP = 60.0       # é«˜è´Ÿè·é˜ˆå€¼
    TH_DN = 50.0       # ä½è´Ÿè·é˜ˆå€¼
    
    async def initialize_model(self) -> None:
        """åŠ è½½EEGè„‘è´Ÿè·æ¨¡å‹"""
        self.logger.info("æ­£åœ¨åŠ è½½EEGè„‘è´Ÿè·æ¨¡å‹...")
        
        # ç¡®å®šæ¨¡å‹è·¯å¾„ - ä»æ ¹ç›®å½•çš„models_dataæ–‡ä»¶å¤¹åŠ è½½
        project_root = Path(__file__).parent.parent.parent
        models_dir = project_root / "models_data" / "eeg_models"
        
        self.scaler_path = models_dir / "mymodel_scaler.joblib"
        self.calibrator_path = models_dir / "mymodel_calibrator.joblib"
        
        if not self.scaler_path.exists():
            raise FileNotFoundError(f"Scaleræ–‡ä»¶ä¸å­˜åœ¨: {self.scaler_path}")
        if not self.calibrator_path.exists():
            raise FileNotFoundError(f"Calibratoræ–‡ä»¶ä¸å­˜åœ¨: {self.calibrator_path}")
        
        self.logger.info("åŠ è½½æ¨¡å‹ç»„ä»¶...")
        print("="*60)
        print("ğŸ“¦ åŠ è½½EEGè„‘è´Ÿè·æ¨¡å‹...")
        print("="*60)
        
        # åŠ è½½scalerå’Œcalibrator
        print(f"  [1/2] åŠ è½½ç‰¹å¾ç¼©æ”¾å™¨ (scaler)...")
        self.scaler = joblib.load(str(self.scaler_path))
        print(f"  âœ“ ScaleråŠ è½½å®Œæˆ")
        
        print(f"  [2/2] åŠ è½½åˆ†ç±»å™¨ (calibrator)...")
        self.calibrator = joblib.load(str(self.calibrator_path))
        print(f"  âœ“ CalibratoråŠ è½½å®Œæˆ")
        
        print("="*60)
        self.logger.info("âœ… EEGè„‘è´Ÿè·æ¨¡å‹åŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ–EMAçŠ¶æ€
        self.ema = None
        self.state = "low"
    
    async def process_inference(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒEEGè„‘è´Ÿè·æ¨ç†
        
        Args:
            data: è¾“å…¥æ•°æ®,åŒ…å«:
                - eeg_signal: EEGä¿¡å·æ•°æ® (2Dæ•°ç»„ [N, 2] æˆ– base64ç¼–ç çš„CSV)
                - sampling_rate: é‡‡æ ·ç‡ (é»˜è®¤250Hz)
                - subject_id: è¢«è¯•ID (å¯é€‰)
        
        Returns:
            æ¨ç†ç»“æœ:
                - brain_load_score: è„‘è´Ÿè·åˆ†æ•° (0-100)
                - state: çŠ¶æ€ ("low"/"high")
                - window_results: å„çª—å£è¯¦ç»†ç»“æœ
        """
        start_time = time.time()
        
        # è·å–è¾“å…¥å‚æ•°
        eeg_signal = data.get("eeg_signal", None)
        sampling_rate = data.get("sampling_rate", FS)
        subject_id = data.get("subject_id", "unknown")
        
        # æ‰“å°è¾“å…¥ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ“¥ æ¥æ”¶åˆ°EEGæ¨ç†è¯·æ±‚")
        print(f"{'='*60}")
        print(f"  è¢«è¯•ID: {subject_id}")
        print(f"  é‡‡æ ·ç‡: {sampling_rate}Hz")
        
        if eeg_signal is None:
            print(f"âš ï¸  æœªæä¾›EEGä¿¡å·,è¿”å›é»˜è®¤å€¼")
            print(f"{'='*60}\n")
            return {
                "brain_load_score": 0.0,
                "state": "low",
                "window_results": [],
                "message": "æœªæä¾›EEGä¿¡å·"
            }
        
        try:
            # è§£æEEGä¿¡å·
            if isinstance(eeg_signal, str):
                # Base64ç¼–ç çš„CSV/TXTæ–‡ä»¶
                print(f"  è§£ç EEGä¿¡å·æ–‡ä»¶...")
                signal_bytes = base64.b64decode(eeg_signal)
                
                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='wb', suffix='.txt', delete=False) as tmp:
                    tmp.write(signal_bytes)
                    tmp_path = tmp.name
                
                try:
                    # è¯»å–ä¿¡å·
                    raw = read_eeg_txt_two_channels(tmp_path)
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)
                        
            elif isinstance(eeg_signal, list):
                # ç›´æ¥æä¾›çš„æ•°ç»„
                raw = np.array(eeg_signal, dtype=np.float64)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„EEGä¿¡å·æ ¼å¼: {type(eeg_signal)}")
            
            print(f"  âœ“ ä¿¡å·è§£æå®Œæˆ: shape={raw.shape}")
            
            if raw.shape[1] != 2:
                raise ValueError(f"EEGä¿¡å·å¿…é¡»æ˜¯åŒé€šé“ (Fp1, Fp2), å½“å‰: {raw.shape[1]}é€šé“")
            
            # é¢„å¤„ç†
            print(f"  ğŸ”§ ä¿¡å·é¢„å¤„ç†...")
            raw = preprocess_eeg(raw, fs=sampling_rate)
            print(f"  âœ“ é¢„å¤„ç†å®Œæˆ: å¸¦é€šæ»¤æ³¢ + é™·æ³¢å™¨")
            
            # åˆ†çª—
            print(f"  ğŸ“Š ä¿¡å·åˆ†çª—...")
            wins, starts = segment_windows(
                raw, 
                fs=sampling_rate, 
                win_sec=self.WIN_SEC, 
                step_sec=self.STEP_SEC
            )
            print(f"  âœ“ åˆ†çª—å®Œæˆ: {len(wins)}ä¸ªçª—å£")
            
            if len(wins) == 0:
                print(f"âš ï¸  ä¿¡å·å¤ªçŸ­,æ— æ³•åˆ†çª—")
                print(f"{'='*60}\n")
                return {
                    "brain_load_score": 0.0,
                    "state": self.state,
                    "window_results": [],
                    "message": "ä¿¡å·å¤ªçŸ­,æ— æ³•åˆ†çª—"
                }
            
            # æå–ç‰¹å¾
            print(f"  ğŸ” æå–ç‰¹å¾...")
            X, feat_names, mask = extract_features_batch(
                wins, 
                fs=sampling_rate, 
                reject_artifacts=True
            )
            starts = starts[mask]
            
            if X.shape[0] == 0:
                print(f"âš ï¸  æ‰€æœ‰çª—å£éƒ½è¢«åˆ¤å®šä¸ºä¼ªè¿¹")
                print(f"{'='*60}\n")
                return {
                    "brain_load_score": 0.0,
                    "state": self.state,
                    "window_results": [],
                    "message": "æ‰€æœ‰çª—å£éƒ½è¢«åˆ¤å®šä¸ºä¼ªè¿¹"
                }
            
            print(f"  âœ“ ç‰¹å¾æå–å®Œæˆ: {X.shape[0]}ä¸ªæœ‰æ•ˆçª—å£, {X.shape[1]}ç»´ç‰¹å¾")
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            print(f"  ğŸ“ ç‰¹å¾æ ‡å‡†åŒ–...")
            Xn = self.scaler.transform(X)
            print(f"  âœ“ æ ‡å‡†åŒ–å®Œæˆ")
            
            # æ¨ç†
            print(f"  ğŸ§  æ¨¡å‹æ¨ç†ä¸­...")
            window_results = []
            
            for i in range(Xn.shape[0]):
                # é¢„æµ‹æ¦‚ç‡
                proba = self.calibrator.predict_proba(Xn[i:i+1])[:, 1][0]
                score_raw = 100.0 * float(proba)
                
                # æŒ‡æ•°ç§»åŠ¨å¹³å‡
                if self.ema is None:
                    self.ema = score_raw
                else:
                    self.ema = self.EMA_ALPHA * self.ema + (1 - self.EMA_ALPHA) * score_raw
                
                # è¿Ÿæ»åˆ¤å®š
                prev_state = self.state
                if self.state == "low" and self.ema >= self.TH_UP:
                    self.state = "high"
                elif self.state == "high" and self.ema <= self.TH_DN:
                    self.state = "low"
                
                # æ—¶é—´èŒƒå›´
                t_start = starts[i] / sampling_rate
                t_end = t_start + self.WIN_SEC
                
                state_change = " (â†‘)" if (prev_state == "low" and self.state == "high") else \
                              (" (â†“)" if (prev_state == "high" and self.state == "low") else "")
                
                print(f"    çª—å£ {i+1}/{Xn.shape[0]}: "
                      f"t=[{t_start:.2f}s, {t_end:.2f}s], "
                      f"raw={score_raw:.2f}, "
                      f"ema={self.ema:.2f}, "
                      f"state={self.state}{state_change}")
                
                window_results.append({
                    "window_index": i,
                    "t_start_s": round(float(t_start), 3),
                    "t_end_s": round(float(t_end), 3),
                    "score_raw": round(score_raw, 3),
                    "score_ema": round(float(self.ema), 3),
                    "state": self.state,
                    "state_changed": prev_state != self.state
                })
            
            print(f"  âœ“ æ¨ç†å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"æ¨ç†å¤±è´¥: {e}", exc_info=True)
            print(f"âŒ æ¨ç†å¤±è´¥: {e}")
            print(f"{'='*60}\n")
            raise
        
        inference_time = time.time() - start_time
        
        # æœ€ç»ˆåˆ†æ•°ä½¿ç”¨EMA
        final_score = float(self.ema) if self.ema is not None else 0.0
        
        print(f"\nğŸ“ˆ æ¨ç†ç»“æœ:")
        print(f"  è„‘è´Ÿè·åˆ†æ•°: {final_score:.2f}/100")
        print(f"  å½“å‰çŠ¶æ€: {self.state}")
        print(f"  æœ‰æ•ˆçª—å£æ•°: {len(window_results)}")
        print(f"  æ€»è€—æ—¶: {inference_time*1000:.0f}ms")
        print(f"{'='*60}\n")
        
        # è®°å½•æ¨ç†æ—¥å¿—
        self.logger.info(
            f"EEGæ¨ç†å®Œæˆ: åˆ†æ•°={round(final_score, 2)}, "
            f"çŠ¶æ€={self.state}, "
            f"çª—å£æ•°={len(window_results)}, "
            f"è€—æ—¶={inference_time*1000:.0f}ms"
        )
        
        result = {
            "brain_load_score": round(final_score, 2),
            "state": self.state,
            "window_results": window_results,
            "inference_time_ms": round(inference_time * 1000, 2),
            "num_windows": len(window_results),
            "subject_id": subject_id
        }
        
        self.logger.debug(
            f"æ¨ç†å®Œæˆ: è„‘è´Ÿè·åˆ†æ•°={result['brain_load_score']}, "
            f"çŠ¶æ€={result['state']}, "
            f"çª—å£æ•°={result['num_windows']}"
        )
        
        return result
    
    async def cleanup(self) -> None:
        """æ¸…ç†æ¨¡å‹èµ„æº"""
        self.logger.info("æ­£åœ¨æ¸…ç†EEGæ¨¡å‹èµ„æº...")
        
        # é‡Šæ”¾æ¨¡å‹
        self.scaler = None
        self.calibrator = None
        
        # é‡ç½®çŠ¶æ€
        self.ema = None
        self.state = "low"
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
    log_dir = Path(__file__).parent.parent.parent / "logs" / "model"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "eeg_backend.log"
    
    # åˆ›å»ºæ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    root_logger.addHandler(file_handler)
    
    logging.info(f"ğŸ“ æ—¥å¿—ä¿å­˜åˆ°: {log_file}")
    
    # æ¨¡å‹åç«¯é…ç½®
    config = {
        "model_type": "eeg",
        "host": "127.0.0.1",
        "port": 8769  # ä½¿ç”¨ç‹¬ç«‹ç«¯å£
    }
    
    # åˆ›å»ºå¹¶è¿è¡Œåç«¯
    backend = EEGBackend(config)
    
    print("\n" + "=" * 70)
    print("EEGè„‘è´Ÿè·æ¨¡å‹åç«¯")
    print("=" * 70)
    print(f"ç›‘å¬åœ°å€: ws://{config['host']}:{config['port']}")
    print(f"æ¨¡å‹ç±»å‹: {config['model_type']}")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 70 + "\n")
    
    backend.run()


if __name__ == "__main__":
    main()
