"""EEGè„‘è´Ÿè·æ¨¡å‹ - ç›´æ¥é›†æˆç‰ˆæœ¬

é›†æˆ eeg_algorithms/ ä¸­çš„ç®—æ³•åº“è¿›è¡Œåœ¨çº¿æ¨ç†
"""

import base64
import gc
import logging
import os
import tempfile
import time
from pathlib import Path
from typing import Any, Dict, List

import numpy as np

from .base_inference_model import BaseInferenceModel

try:
    import joblib
    from .eeg_algorithms.eeg_utils import (
        FS,
        preprocess_eeg,
        segment_windows,
        extract_features_batch,
        read_eeg_txt_two_channels
    )
    HAS_DEPS = True
except ImportError as e:
    HAS_DEPS = False
    _import_error = e


class EEGModel(BaseInferenceModel):
    """EEGè„‘è´Ÿè·æ¨¡å‹ï¼ˆé›†æˆç‰ˆæœ¬ï¼‰
    
    ç›´æ¥åœ¨åç«¯è¿›ç¨‹ä¸­è¿è¡Œï¼Œæ— éœ€ç‹¬ç«‹è¿›ç¨‹
    
    åŠŸèƒ½:
    - å¤„ç†åŒé€šé“EEGä¿¡å· (Fp1, Fp2)
    - æå–æ—¶é¢‘åŸŸç‰¹å¾
    - è¾“å‡ºè„‘è´Ÿè·åˆ†æ•° (0-100)
    """
    
    # æ¨¡å‹å‚æ•°
    WIN_SEC = 2.0      # çª—å£é•¿åº¦(ç§’)
    STEP_SEC = 1.0     # æ»‘åŠ¨æ­¥é•¿(ç§’)
    EMA_ALPHA = 0.7    # æŒ‡æ•°ç§»åŠ¨å¹³å‡ç³»æ•°
    TH_UP = 60.0       # é«˜è´Ÿè·é˜ˆå€¼
    TH_DN = 50.0       # ä½è´Ÿè·é˜ˆå€¼
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–EEGè„‘è´Ÿè·æ¨¡å‹"""
        if not HAS_DEPS:
            raise RuntimeError(f"æ— æ³•åŠ è½½ä¾èµ–: {_import_error}")
        
        # ç¡®å®šæ¨¡å‹è·¯å¾„ - ä»æ ¹ç›®å½•çš„models_dataæ–‡ä»¶å¤¹åŠ è½½
        project_root = Path(__file__).parent.parent.parent
        models_dir = project_root / "models_data" / "eeg_models"
        
        self.scaler_path = models_dir / "mymodel_scaler.joblib"
        self.calibrator_path = models_dir / "mymodel_calibrator.joblib"
        
        if not self.scaler_path.exists():
            raise FileNotFoundError(f"Scaleræ–‡ä»¶ä¸å­˜åœ¨: {self.scaler_path}")
        if not self.calibrator_path.exists():
            raise FileNotFoundError(f"Calibratoræ–‡ä»¶ä¸å­˜åœ¨: {self.calibrator_path}")
        
        # åŠ è½½scalerå’Œcalibrator
        self.logger.info("åŠ è½½EEGæ¨¡å‹ç»„ä»¶...")
        self.scaler = joblib.load(str(self.scaler_path))
        self.logger.info("  âœ“ ScaleråŠ è½½å®Œæˆ")
        
        self.calibrator = joblib.load(str(self.calibrator_path))
        self.logger.info("  âœ“ CalibratoråŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ–EMAçŠ¶æ€
        self.ema = None
        self.state = "low"
        
        self.logger.info("âœ… EEGè„‘è´Ÿè·æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def infer(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒEEGè„‘è´Ÿè·æ¨ç†
        
        æ”¯æŒä¸‰ç§è¾“å…¥æ¨¡å¼ï¼š
        1. å†…å­˜æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼š
           - memory_mode: bool = True
           - eeg_signal: np.ndarray - EEGä¿¡å·æ•°ç»„ [N, 2]
           - sampling_rate: int = 250
           - subject_id: str = "unknown"
           
        2. æ–‡ä»¶è·¯å¾„æ¨¡å¼ï¼š
           - file_mode: bool = True
           - eeg_file_path: str - EEGæ•°æ®æ–‡ä»¶è·¯å¾„
           - sampling_rate: int = 250
           - subject_id: str = "unknown"
           
        3. base64æ•°æ®æ¨¡å¼ï¼ˆå…¼å®¹ï¼‰ï¼š
           - eeg_signal: str - base64ç¼–ç çš„æ–‡ä»¶
           - sampling_rate: int = 250
           - subject_id: str = "unknown"
        
        Args:
            data: è¾“å…¥æ•°æ®å­—å…¸
        
                Returns:
                        æ¨ç†ç»“æœ:
                                - status: "success" | "no-data" | "error"
                                    - no-data: è¾“å…¥æœ‰æ•ˆä½†å½“å‰æ—¶é—´çª—å†…æ²¡æœ‰å¯ç”¨çª—å£ï¼ˆå¤ªçŸ­æˆ–å…¨éƒ¨åˆ¤ä¸ºä¼ªè¿¹ï¼‰ï¼Œå»ºè®®ä¸Šå±‚è·³è¿‡å‘å¸ƒ
                                - brain_load_score: è„‘è´Ÿè·åˆ†æ•° (0-100)
                                - state: çŠ¶æ€ ("low"/"high")
                                - window_results: å„çª—å£è¯¦ç»†ç»“æœ
        """
        # ä¼˜å…ˆä½¿ç”¨å†…å­˜æ¨¡å¼
        if data.get("memory_mode") == True:
            return self._infer_from_memory(data)
        elif data.get("file_mode") == True:
            return self._infer_from_file(data)
        else:
            return self._infer_from_base64(data)
    
    def _infer_from_memory(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»å†…å­˜ä¸­çš„numpyæ•°ç»„ç›´æ¥æ¨ç†ï¼ˆé›¶I/Oå¼€é”€ï¼‰"""
        start_time = time.time()
        
        eeg_signal = data.get("eeg_signal")
        sampling_rate = data.get("sampling_rate", FS)
        subject_id = data.get("subject_id", "unknown")
        
        if eeg_signal is None:
            return {
                "status": "error",
                "error": "æœªæä¾›EEGä¿¡å·",
                "brain_load_score": 0.0,
                "state": self.state
            }
        
        try:
            # ç¡®ä¿æ˜¯numpyæ•°ç»„
            if not isinstance(eeg_signal, np.ndarray):
                eeg_signal = np.array(eeg_signal, dtype=np.float64)
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if eeg_signal.size == 0:
                raise ValueError(f"EEGä¿¡å·ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
            
            # æ£€æŸ¥ç»´åº¦
            if eeg_signal.ndim != 2:
                raise ValueError(f"EEGä¿¡å·å¿…é¡»æ˜¯2ç»´æ•°ç»„ [n_samples, 2], å½“å‰ç»´åº¦: {eeg_signal.ndim}")
            
            if eeg_signal.shape[1] != 2:
                raise ValueError(f"EEGä¿¡å·å¿…é¡»æ˜¯åŒé€šé“ (Fp1, Fp2), å½“å‰: {eeg_signal.shape[1]}é€šé“")
            
            # é¢„å¤„ç†
            raw = preprocess_eeg(eeg_signal, fs=sampling_rate)
            
            # åˆ†çª—
            wins, starts = segment_windows(
                raw,
                fs=sampling_rate,
                win_sec=self.WIN_SEC,
                step_sec=self.STEP_SEC
            )
            
            if len(wins) == 0:
                # æ— æœ‰æ•ˆçª—å£ï¼šæ ‡è®°ä¸º no-dataï¼Œé¿å…ä¸Šå±‚å°†å…¶è§†ä¸ºæœ‰æ•ˆ0åˆ†
                return {
                    "status": "no-data",
                    "error": "ä¿¡å·å¤ªçŸ­ï¼Œæ— æ³•åˆ†çª—",
                    "brain_load_score": 0.0,
                    "state": self.state,
                    "window_results": [],
                    "num_windows": 0,
                    "inference_mode": "memory"
                }
            
            # æå–ç‰¹å¾
            X, feat_names, mask = extract_features_batch(
                wins,
                fs=sampling_rate,
                reject_artifacts=True
            )
            starts = starts[mask]
            
            if X.shape[0] == 0:
                # å…¨éƒ¨ä¼ªè¿¹ï¼šæ ‡è®°ä¸º no-dataï¼Œé¿å…ä¸Šå±‚å°†å…¶è§†ä¸ºæœ‰æ•ˆ0åˆ†
                return {
                    "status": "no-data",
                    "error": "æ‰€æœ‰çª—å£éƒ½è¢«åˆ¤å®šä¸ºä¼ªè¿¹",
                    "brain_load_score": 0.0,
                    "state": self.state,
                    "window_results": [],
                    "num_windows": 0,
                    "inference_mode": "memory"
                }
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            Xn = self.scaler.transform(X)
            
            # æ¨ç†
            window_results = []
            
            for i in range(Xn.shape[0]):
                # é¢„æµ‹æ¦‚ç‡
                proba = self.calibrator.predict_proba(Xn[i:i+1])[:, 1][0]
                score_raw = 100.0 * float(proba)
                
                # æŒ‡æ•°ç§»åŠ¨å¹³å‡
                if self.ema is None:
                    self.ema = score_raw
                else:
                    self.ema = self.EMA_ALPHA * self.ema + (1 - self.EMA_ALPHA) * score_raw
                
                # è¿Ÿæ»åˆ¤å®š
                prev_state = self.state
                if self.state == "low" and self.ema >= self.TH_UP:
                    self.state = "high"
                elif self.state == "high" and self.ema <= self.TH_DN:
                    self.state = "low"
                
                # æ—¶é—´èŒƒå›´
                t_start = starts[i] / sampling_rate
                t_end = t_start + self.WIN_SEC
                
                window_results.append({
                    "window_index": i,
                    "t_start_s": round(float(t_start), 3),
                    "t_end_s": round(float(t_end), 3),
                    "score_raw": round(score_raw, 3),
                    "score_ema": round(float(self.ema), 3),
                    "state": self.state,
                    "state_changed": prev_state != self.state
                })
            
            
            inference_time = (time.time() - start_time) * 1000
            
            # æœ€ç»ˆåˆ†æ•°ä½¿ç”¨EMA
            final_score = float(self.ema) if self.ema is not None else 0.0
            
            # å•è¡Œè¾“å‡ºæ¨ç†ç»“æœ
            load_level = "æ­£å¸¸ğŸ˜Š" if final_score < 30 else "è½»åº¦è´Ÿè·ğŸ˜" if final_score < 60 else "é‡åº¦è´Ÿè·ğŸ”¥"
            self.logger.info(
                f"ğŸ§  è„‘è´Ÿè·: {round(final_score, 2)} ({load_level}, {self.state}, "
                f"{len(window_results)}çª—å£, {round(inference_time, 1)}ms)"
            )
            
            return {
                "status": "success",
                "brain_load_score": round(final_score, 2),
                "state": self.state,
                "window_results": window_results,
                "num_windows": len(window_results),
                "subject_id": subject_id,
                "inference_mode": "memory",
                "inference_time_ms": round(inference_time, 1)
            }
            
        except Exception as e:
            self.logger.error(f"å†…å­˜æ¨ç†å¤±è´¥: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "brain_load_score": 0.0,
                "state": self.state
            }
    
    def _infer_from_file(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»æ–‡ä»¶è·¯å¾„è¯»å–æ•°æ®å¹¶æ¨ç†"""
        from pathlib import Path
        
        start_time = time.time()
        
        eeg_file_path = data.get("eeg_file_path")
        sampling_rate = data.get("sampling_rate", FS)
        subject_id = data.get("subject_id", "unknown")
        
        if not eeg_file_path:
            return {
                "status": "error",
                "error": "ç¼ºå°‘å¿…éœ€çš„EEGæ–‡ä»¶è·¯å¾„",
                "brain_load_score": 0.0,
                "state": self.state
            }
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not Path(eeg_file_path).exists():
            return {
                "status": "error",
                "error": f"EEGæ–‡ä»¶ä¸å­˜åœ¨: {eeg_file_path}",
                "brain_load_score": 0.0,
                "state": self.state
            }
        
        try:
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ§  EEGè„‘è´Ÿè·åˆ†æ - æ–‡ä»¶æ¨¡å¼")
            self.logger.info(f"{'='*60}")
            self.logger.info(f"ğŸ“‚ æ–‡ä»¶è·¯å¾„: {Path(eeg_file_path).name}")
            self.logger.info(f"   è¢«è¯•ID: {subject_id}")
            self.logger.info(f"   é‡‡æ ·ç‡: {sampling_rate}Hz")
            
            # è¯»å–ä¿¡å·
            raw = read_eeg_txt_two_channels(str(eeg_file_path))
            self.logger.info(f"  âœ“ ä¿¡å·è¯»å–å®Œæˆ: shape={raw.shape}")
            
            # ä½¿ç”¨å†…å­˜æ¨¡å¼å¤„ç†ï¼ˆé¿å…é‡å¤ä»£ç ï¼‰
            return self._infer_from_memory({
                "memory_mode": True,
                "eeg_signal": raw,
                "sampling_rate": sampling_rate,
                "subject_id": subject_id
            })
            
        except Exception as e:
            self.logger.error(f"ä»æ–‡ä»¶æ¨ç†å¤±è´¥: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "brain_load_score": 0.0,
                "state": self.state
            }
    
    def _infer_from_base64(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»base64æ•°æ®æ¨ç†ï¼ˆåŸæœ‰é€»è¾‘ï¼Œç”¨äºè¿œç¨‹é€šä¿¡ï¼‰"""
        start_time = time.time()
        
        eeg_signal = data.get("eeg_signal", None)
        sampling_rate = data.get("sampling_rate", FS)
        subject_id = data.get("subject_id", "unknown")
        
        if eeg_signal is None:
            return {
                "status": "error",
                "error": "æœªæä¾›EEGä¿¡å·",
                "brain_load_score": 0.0,
                "state": self.state
            }
        
        try:
            # è§£æEEGä¿¡å·
            if isinstance(eeg_signal, str):
                # Base64ç¼–ç çš„CSV/TXTæ–‡ä»¶
                self.logger.info(f"è§£ç EEGä¿¡å·æ–‡ä»¶...")
                signal_bytes = base64.b64decode(eeg_signal)
                
                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='wb', suffix='.txt', delete=False) as tmp:
                    tmp.write(signal_bytes)
                    tmp_path = tmp.name
                
                try:
                    # è¯»å–ä¿¡å·
                    raw = read_eeg_txt_two_channels(tmp_path)
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)
                        
            elif isinstance(eeg_signal, list):
                # ç›´æ¥æä¾›çš„æ•°ç»„
                raw = np.array(eeg_signal, dtype=np.float64)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„EEGä¿¡å·æ ¼å¼: {type(eeg_signal)}")
            
            # ä½¿ç”¨å†…å­˜æ¨¡å¼å¤„ç†
            return self._infer_from_memory({
                "memory_mode": True,
                "eeg_signal": raw,
                "sampling_rate": sampling_rate,
                "subject_id": subject_id
            })
            
        except Exception as e:
            self.logger.error(f"base64æ¨ç†å¤±è´¥: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "brain_load_score": 0.0,
                "state": self.state
            }
    
    def cleanup(self) -> None:
        """æ¸…ç†æ¨¡å‹èµ„æº"""
        if hasattr(self, 'scaler'):
            self.scaler = None
        if hasattr(self, 'calibrator'):
            self.calibrator = None
        
        # é‡ç½®çŠ¶æ€
        self.ema = None
        self.state = "low"
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()


__all__ = ["EEGModel"]
