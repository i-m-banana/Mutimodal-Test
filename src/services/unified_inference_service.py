"""ç»Ÿä¸€æ¨ç†æœåŠ¡ - æ”¯æŒé›†æˆæ¨¡å¼å’Œè¿œç¨‹ä»£ç†æ¨¡å¼

æ ¹æ®é…ç½®å†³å®šæ˜¯ç›´æ¥è°ƒç”¨é›†æˆæ¨¡å‹ï¼Œè¿˜æ˜¯é€šè¿‡WebSocketä»£ç†åˆ°è¿œç¨‹è¿›ç¨‹
"""

import importlib
import logging
from typing import Any, Dict, List, Optional
from concurrent.futures import Future, ThreadPoolExecutor

from ..constants import EventTopic
from ..core.event_bus import Event, EventBus
from ..models.base_inference_model import BaseInferenceModel

try:
    from ..interfaces.model_ws_client import ModelBackendClient
    HAS_CLIENT = True
except ImportError:
    HAS_CLIENT = False


class UnifiedInferenceService:
    """ç»Ÿä¸€æ¨ç†æœåŠ¡
    
    æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼š
    1. integrated: æ¨¡å‹ç›´æ¥é›†æˆåœ¨è¿›ç¨‹ä¸­
    2. remote: é€šè¿‡WebSocketä»£ç†åˆ°ç‹¬ç«‹è¿›ç¨‹
    
    å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­çµæ´»åˆ‡æ¢æ¨¡å¼ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
    """
    
    def __init__(
        self,
        bus: EventBus,
        model_configs: List[Dict[str, Any]],
        *,
        logger: Optional[logging.Logger] = None
    ):
        """åˆå§‹åŒ–ç»Ÿä¸€æ¨ç†æœåŠ¡
        
        Args:
            bus: äº‹ä»¶æ€»çº¿
            model_configs: æ¨¡å‹é…ç½®åˆ—è¡¨
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.bus = bus
        self.model_configs = model_configs
        self.logger = logger or logging.getLogger("service.inference")
        
        # é›†æˆæ¨¡å¼çš„æ¨¡å‹å®ä¾‹
        self.integrated_models: Dict[str, BaseInferenceModel] = {}
        
        # è¿œç¨‹æ¨¡å¼çš„å®¢æˆ·ç«¯å®ä¾‹
        self.remote_clients: Dict[str, "ModelBackendClient"] = {}
        
        # çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥å¤„ç†
        self._executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="inference")
        
        self._running = False
    
    def start(self) -> None:
        """å¯åŠ¨æ¨ç†æœåŠ¡"""
        if self._running:
            self.logger.warning("æ¨ç†æœåŠ¡å·²åœ¨è¿è¡Œ")
            return
        
        self.logger.info("å¯åŠ¨ç»Ÿä¸€æ¨ç†æœåŠ¡...")
        
        enabled_count = 0
        for config in self.model_configs:
            if not config.get("enabled", True):
                self.logger.info(f"è·³è¿‡ç¦ç”¨çš„æ¨¡å‹: {config.get('name')}")
                continue
            
            model_name = config["name"]
            model_type = config["type"]
            mode = config.get("mode", "remote")
            
            if mode == "integrated":
                # é›†æˆæ¨¡å¼ï¼šç›´æ¥åŠ è½½æ¨¡å‹
                enabled_count += self._start_integrated_model(model_name, model_type, config)
            elif mode == "remote":
                # è¿œç¨‹æ¨¡å¼ï¼šè¿æ¥åˆ°æ¨¡å‹åç«¯
                enabled_count += self._start_remote_client(model_name, model_type, config)
            else:
                self.logger.error(f"æœªçŸ¥çš„æ¨¡å‹æ¨¡å¼: {mode} (æ¨¡å‹: {model_name})")
        
        if enabled_count == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return
        
        # è®¢é˜…éœ€è¦æ¨ç†çš„äº‹ä»¶
        self.bus.subscribe(EventTopic.MULTIMODAL_SNAPSHOT, self._on_multimodal_data)
        self.logger.info(f"å·²è®¢é˜…äº‹ä»¶: {EventTopic.MULTIMODAL_SNAPSHOT.value}")
        
        self._running = True
        self.logger.info(f"âœ… ç»Ÿä¸€æ¨ç†æœåŠ¡å·²å¯åŠ¨ (å…± {enabled_count} ä¸ªæ¨¡å‹)")
    
    def _start_integrated_model(
        self,
        model_name: str,
        model_type: str,
        config: Dict[str, Any]
    ) -> int:
        """å¯åŠ¨é›†æˆæ¨¡å¼çš„æ¨¡å‹
        
        Returns:
            1 if success, 0 if failed
        """
        integrated_config = config.get("integrated", {})
        class_path = integrated_config.get("class")
        options = integrated_config.get("options", {})
        
        if not class_path:
            self.logger.error(f"é›†æˆæ¨¡å‹ç¼ºå°‘ class é…ç½®: {model_name}")
            return 0
        
        try:
            # åŠ¨æ€å¯¼å…¥æ¨¡å‹ç±»
            module_name, _, class_name = class_path.rpartition(".")
            if not module_name.startswith("src."):
                module_name = f"src.{module_name}"
            
            module = importlib.import_module(module_name)
            model_class = getattr(module, class_name)
            
            # å®ä¾‹åŒ–å¹¶åŠ è½½æ¨¡å‹
            model = model_class(model_name, logger=self.logger, **options)
            model.load()
            
            self.integrated_models[model_type] = model
            self.logger.info(f"âœ… é›†æˆæ¨¡å‹å·²åŠ è½½: {model_name} ({model_type})")
            return 1
            
        except Exception as e:
            self.logger.error(f"åŠ è½½é›†æˆæ¨¡å‹å¤±è´¥ ({model_name}): {e}", exc_info=True)
            return 0
    
    def _start_remote_client(
        self,
        model_name: str,
        model_type: str,
        config: Dict[str, Any]
    ) -> int:
        """å¯åŠ¨è¿œç¨‹æ¨¡å¼çš„å®¢æˆ·ç«¯
        
        Returns:
            1 if success, 0 if failed
        """
        if not HAS_CLIENT:
            self.logger.error(f"WebSocketå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œæ— æ³•å¯åŠ¨è¿œç¨‹æ¨¡å‹: {model_name}")
            return 0
        
        remote_config = config.get("remote", {})
        host = remote_config.get("host", "127.0.0.1")
        port = remote_config.get("port", 8766)
        url = f"ws://{host}:{port}"
        
        reconnect = remote_config.get("reconnect", True)
        reconnect_interval = remote_config.get("reconnect_interval", 5.0)
        
        try:
            client = ModelBackendClient(
                model_type,
                url,
                reconnect=reconnect,
                reconnect_interval=reconnect_interval
            )
            client.start()
            
            self.remote_clients[model_type] = client
            self.logger.info(f"âœ… è¿œç¨‹æ¨¡å‹å®¢æˆ·ç«¯å·²å¯åŠ¨: {model_name} ({model_type}) -> {url}")
            return 1
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨è¿œç¨‹æ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥ ({model_name}): {e}", exc_info=True)
            return 0
    
    def stop(self) -> None:
        """åœæ­¢æ¨ç†æœåŠ¡"""
        if not self._running:
            return
        
        self.logger.info("åœæ­¢ç»Ÿä¸€æ¨ç†æœåŠ¡...")
        
        # å–æ¶ˆè®¢é˜…
        try:
            self.bus.unsubscribe(EventTopic.MULTIMODAL_SNAPSHOT, self._on_multimodal_data)
        except Exception as e:
            self.logger.error(f"å–æ¶ˆè®¢é˜…å¤±è´¥: {e}")
        
        # å¸è½½é›†æˆæ¨¡å‹
        for model_type, model in self.integrated_models.items():
            try:
                model.unload()
                self.logger.info(f"å·²å¸è½½é›†æˆæ¨¡å‹: {model_type}")
            except Exception as e:
                self.logger.error(f"å¸è½½é›†æˆæ¨¡å‹å¤±è´¥ ({model_type}): {e}")
        self.integrated_models.clear()
        
        # åœæ­¢è¿œç¨‹å®¢æˆ·ç«¯
        for model_type, client in self.remote_clients.items():
            try:
                client.stop()
                self.logger.info(f"å·²åœæ­¢è¿œç¨‹å®¢æˆ·ç«¯: {model_type}")
            except Exception as e:
                self.logger.error(f"åœæ­¢è¿œç¨‹å®¢æˆ·ç«¯å¤±è´¥ ({model_type}): {e}")
        self.remote_clients.clear()
        
        # å…³é—­çº¿ç¨‹æ± 
        self._executor.shutdown(wait=True)
        
        self._running = False
        self.logger.info("âœ… ç»Ÿä¸€æ¨ç†æœåŠ¡å·²åœæ­¢")
    
    def _on_multimodal_data(self, event: Event) -> None:
        """å¤„ç†å¤šæ¨¡æ€æ•°æ®ï¼Œåˆ†å‘åˆ°å„æ¨¡å‹"""
        payload = event.payload or {}
        
        # æå–æ•°æ®
        rgb_b64 = payload.get("rgb_b64")
        depth_b64 = payload.get("depth_b64")
        timestamp = payload.get("timestamp")
        frame_count = payload.get("frame_count")
        
        if not rgb_b64:
            self.logger.warning("å¤šæ¨¡æ€æ•°æ®ç¼ºå°‘RGBå›¾åƒ")
            return
        
        metadata = {
            "timestamp": timestamp,
            "frame_count": frame_count
        }
        
        # åˆ†å‘åˆ°ç–²åŠ³åº¦æ¨¡å‹
        if "fatigue" in self.integrated_models or "fatigue" in self.remote_clients:
            self._submit_inference("fatigue", {
                "rgb_frames": [rgb_b64],
                "depth_frames": [depth_b64] if depth_b64 else [],
                "eyetrack_samples": [],
                "elapsed_time": 5.0
            }, metadata)
        
        # åˆ†å‘åˆ°æƒ…ç»ªæ¨¡å‹
        # TODO: éœ€è¦å®Œæ•´çš„æ ·æœ¬æ•°æ®ï¼ˆè§†é¢‘ã€éŸ³é¢‘ã€æ–‡æœ¬ï¼‰
        
        # TODO: å…¶ä»–æ¨¡å‹
    
    def _submit_inference(
        self,
        model_type: str,
        data: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> None:
        """æäº¤æ¨ç†ä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰"""
        def _infer():
            try:
                # é€‰æ‹©æ¨ç†æ–¹å¼
                if model_type in self.integrated_models:
                    result = self._infer_integrated(model_type, data)
                elif model_type in self.remote_clients:
                    result = self._infer_remote(model_type, data)
                else:
                    self.logger.warning(f"æ¨¡å‹æœªåŠ è½½: {model_type}")
                    return
                
                # å‘å¸ƒç»“æœ
                if result:
                    self._publish_result(model_type, result, metadata)
                    
            except Exception as e:
                self.logger.error(f"æ¨ç†ä»»åŠ¡å¤±è´¥ ({model_type}): {e}", exc_info=True)
        
        self._executor.submit(_infer)
    
    def _infer_integrated(
        self,
        model_type: str,
        data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨é›†æˆæ¨¡å‹æ¨ç†"""
        model = self.integrated_models[model_type]
        
        try:
            self.logger.info(f"ğŸ”„ å¼€å§‹é›†æˆæ¨¡å‹æ¨ç†: {model_type}")
            result = model.infer(data)
            
            # è¾“å‡ºæ¨ç†ç»“æœå…³é”®ä¿¡æ¯
            if result and result.get("status") == "success":
                predictions = result.get("predictions", result)
                if model_type == "fatigue":
                    fatigue_score = predictions.get("fatigue_score", 0)
                    prediction_class = predictions.get("prediction_class", 0)
                    self.logger.info(f"âœ… ç–²åŠ³åº¦æ¨ç†å®Œæˆ: score={fatigue_score:.2f}, class={prediction_class}")
                elif model_type == "emotion":
                    emotion_score = predictions.get("emotion_score", 0)
                    self.logger.info(f"âœ… æƒ…ç»ªæ¨ç†å®Œæˆ: score={emotion_score:.2f}")
                else:
                    self.logger.info(f"âœ… {model_type} æ¨ç†å®Œæˆ: {predictions}")
            else:
                self.logger.warning(f"âš ï¸  {model_type} æ¨ç†è¿”å›å¼‚å¸¸: {result}")
            
            return result
        except Exception as e:
            self.logger.error(f"é›†æˆæ¨¡å‹æ¨ç†å¤±è´¥ ({model_type}): {e}", exc_info=True)
            return None
    
    def _infer_remote(
        self,
        model_type: str,
        data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨è¿œç¨‹å®¢æˆ·ç«¯æ¨ç†"""
        client = self.remote_clients[model_type]
        
        if not client.is_healthy():
            self.logger.warning(f"è¿œç¨‹æ¨¡å‹æœªè¿æ¥: {model_type}")
            return None
        
        try:
            self.logger.info(f"ğŸŒ å‘é€è¿œç¨‹æ¨ç†è¯·æ±‚: {model_type}")
            future = client.send_inference_request(data, timeout=10.0)
            result = future.result(timeout=10.0)
            
            # è¾“å‡ºæ¨ç†ç»“æœå…³é”®ä¿¡æ¯
            if result and result.get("status") == "success":
                predictions = result.get("predictions", result)
                if model_type == "fatigue":
                    fatigue_score = predictions.get("fatigue_score", 0)
                    self.logger.info(f"âœ… è¿œç¨‹ç–²åŠ³åº¦æ¨ç†å®Œæˆ: score={fatigue_score:.2f}")
                elif model_type == "emotion":
                    emotion_score = predictions.get("emotion_score", 0)
                    self.logger.info(f"âœ… è¿œç¨‹æƒ…ç»ªæ¨ç†å®Œæˆ: score={emotion_score:.2f}")
                else:
                    self.logger.info(f"âœ… è¿œç¨‹ {model_type} æ¨ç†å®Œæˆ")
            else:
                self.logger.warning(f"âš ï¸  è¿œç¨‹ {model_type} æ¨ç†è¿”å›å¼‚å¸¸")
            
            return result
        except Exception as e:
            self.logger.error(f"è¿œç¨‹æ¨¡å‹æ¨ç†å¤±è´¥ ({model_type}): {e}", exc_info=True)
            return None
    
    def _publish_result(
        self,
        model_type: str,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> None:
        """å‘å¸ƒæ¨ç†ç»“æœåˆ°äº‹ä»¶æ€»çº¿"""
        if result.get("status") != "success":
            error = result.get("error", "Unknown error")
            self.logger.error(f"{model_type} æ¨ç†å¤±è´¥: {error}")
            return
        
        # æå–é¢„æµ‹ç»“æœï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹ï¼‰
        predictions = {}
        if model_type == "fatigue":
            predictions = {
                "fatigue_score": result.get("fatigue_score", 0),
                "prediction_class": result.get("prediction_class", 0)
            }
        elif model_type == "emotion":
            predictions = {
                "emotion_score": result.get("emotion_score", 0)
            }
        
        # å‘å¸ƒåˆ°äº‹ä»¶æ€»çº¿
        self.bus.publish(Event(
            topic=EventTopic.DETECTION_RESULT,
            payload={
                "detector": f"model_{model_type}",
                "status": "detected",
                "label": model_type,
                "predictions": predictions,
                "timestamp": metadata.get("timestamp"),
                "frame_count": metadata.get("frame_count")
            }
        ))
        
        self.logger.debug(f"âœ… {model_type} æ¨ç†å®Œæˆ: {predictions}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            "running": self._running,
            "integrated_models": list(self.integrated_models.keys()),
            "remote_clients": list(self.remote_clients.keys()),
            "total": len(self.integrated_models) + len(self.remote_clients)
        }


__all__ = ["UnifiedInferenceService"]
