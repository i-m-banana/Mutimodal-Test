"""æµ‹è¯•ç»Ÿä¸€æ¨ç†åç«¯ï¼ˆé›†æˆæ¨¡å¼ï¼‰

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•é›†æˆæ¨¡å¼ä¸‹çš„ç»Ÿä¸€æ¨ç†æœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
ç›´æ¥é€šè¿‡ä¸»åç«¯çš„WebSocketæ¥å£æµ‹è¯•æƒ…ç»ªå’Œç–²åŠ³åº¦æ¨¡å‹
"""

import asyncio
import base64
import json
import sys
from pathlib import Path
import time

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

try:
    import websockets
    import numpy as np
    import cv2
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘ä¾èµ–åº“ - {e}")
    print("è¯·å®‰è£…: pip install websockets numpy opencv-python")
    sys.exit(1)


async def test_backend_connection(uri: str):
    """æµ‹è¯•åç«¯è¿æ¥"""
    print(f"\n[1/5] æµ‹è¯•åç«¯è¿æ¥...")
    try:
        async with websockets.connect(uri, max_size=100 * 1024 * 1024, open_timeout=5) as ws:
            # å…ˆæ¥æ”¶æ¬¢è¿æ¶ˆæ¯
            welcome_msg = await ws.recv()
            welcome_data = json.loads(welcome_msg)
            if welcome_data.get("type") != "welcome":
                print(f"âš ï¸  æœªæ”¶åˆ°é¢„æœŸçš„æ¬¢è¿æ¶ˆæ¯: {welcome_data.get('type')}")
            
            # å‘é€pingæµ‹è¯•
            request = {
                "type": "ping",
                "timestamp": time.time()
            }
            await ws.send(json.dumps(request))
            
            # å¾ªç¯æ¥æ”¶æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°pong
            while True:
                response = json.loads(await ws.recv())
                msg_type = response.get("type")
                
                if msg_type == "pong":
                    print(f"âœ… åç«¯è¿æ¥æˆåŠŸ")
                    print(f"   å»¶è¿Ÿ: {(time.time() - request['timestamp']) * 1000:.2f}ms")
                    return True
                elif msg_type == "event":
                    # è·³è¿‡äº‹ä»¶æ¶ˆæ¯
                    continue
                else:
                    print(f"âŒ æœªçŸ¥å“åº”ç±»å‹: {msg_type}")
                    return False
    except asyncio.TimeoutError:
        print(f"âŒ è¿æ¥è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return False


async def test_model_status(uri: str):
    """æµ‹è¯•æ¨¡å‹çŠ¶æ€"""
    print(f"\n[2/5] æµ‹è¯•æ¨¡å‹çŠ¶æ€...")
    try:
        async with websockets.connect(uri, max_size=100 * 1024 * 1024, open_timeout=5) as ws:
            # å…ˆæ¥æ”¶æ¬¢è¿æ¶ˆæ¯
            welcome_msg = await ws.recv()
            
            request = {
                "type": "get_model_status",
                "timestamp": time.time()
            }
            await ws.send(json.dumps(request))
            
            # å¾ªç¯æ¥æ”¶æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°model_status
            while True:
                response = json.loads(await ws.recv())
                msg_type = response.get("type")
                
                if msg_type == "model_status":
                    models = response.get("models", {})
                    print(f"âœ… æ¨¡å‹çŠ¶æ€æŸ¥è¯¢æˆåŠŸ")
                    print(f"   è¿è¡Œä¸­: {response.get('running', False)}")
                    print(f"   é›†æˆæ¨¡å‹: {models.get('integrated_models', [])}")
                    print(f"   è¿œç¨‹å®¢æˆ·ç«¯: {models.get('remote_clients', [])}")
                    print(f"   æ€»è®¡: {models.get('total', 0)} ä¸ªæ¨¡å‹")
                    return True
                elif msg_type == "event":
                    # è·³è¿‡äº‹ä»¶æ¶ˆæ¯
                    continue
                else:
                    print(f"âŒ æœªçŸ¥å“åº”ç±»å‹: {msg_type}")
                    return False
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ¨¡å‹çŠ¶æ€å¤±è´¥: {e}")
        return False


async def test_fatigue_inference(uri: str):
    """æµ‹è¯•ç–²åŠ³åº¦æ¨ç†"""
    print(f"\n[3/5] æµ‹è¯•ç–²åŠ³åº¦æ¨ç†ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰...")
    try:
        # ç”Ÿæˆè¾ƒå°çš„æ¨¡æ‹Ÿæ•°æ®ï¼ˆå‡å°‘å¸§æ•°å’Œå›¾åƒå°ºå¯¸ä»¥é¿å…æ¶ˆæ¯è¿‡å¤§ï¼‰
        num_frames = 30  # ä»75å¸§å‡å°‘åˆ°30å¸§
        rgb_frames = []
        for i in range(num_frames):
            # ä½¿ç”¨æ›´å°çš„å›¾åƒå°ºå¯¸ (112x112 è€Œä¸æ˜¯ 224x224)
            img = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
            ok, buffer = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 70])  # é™ä½è´¨é‡
            if ok:
                rgb_b64 = base64.b64encode(buffer).decode("ascii")
                rgb_frames.append(rgb_b64)
        
        depth_frames = []
        for i in range(num_frames):
            depth = np.random.randint(0, 255, (112, 112), dtype=np.uint8)
            ok, buffer = cv2.imencode(".png", depth)
            if ok:
                depth_b64 = base64.b64encode(buffer).decode("ascii")
                depth_frames.append(depth_b64)
        
        eyetrack_samples = [list(np.random.rand(8)) for _ in range(num_frames * 5)]
        
        async with websockets.connect(uri, max_size=100 * 1024 * 1024, open_timeout=30) as ws:
            # å…ˆæ¥æ”¶æ¬¢è¿æ¶ˆæ¯
            welcome_msg = await ws.recv()
            
            request = {
                "type": "model_inference",
                "model_type": "fatigue",
                "request_id": "test-fatigue",
                "data": {
                    "rgb_frames": rgb_frames,
                    "depth_frames": depth_frames,
                    "eyetrack_samples": eyetrack_samples,
                    "elapsed_time": 10.0
                },
                "timestamp": time.time()
            }
            
            print(f"   å‘é€æ¨ç†è¯·æ±‚...")
            print(f"   - RGBå¸§æ•°: {len(rgb_frames)}")
            print(f"   - æ·±åº¦å¸§æ•°: {len(depth_frames)}")
            print(f"   - çœ¼åŠ¨æ ·æœ¬æ•°: {len(eyetrack_samples)}")
            
            start_time = time.time()
            await ws.send(json.dumps(request))
            
            # å¾ªç¯æ¥æ”¶æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°model_inference_result
            while True:
                response = json.loads(await ws.recv())
                msg_type = response.get("type")
                
                if msg_type == "model_inference_result":
                    latency = (time.time() - start_time) * 1000
                    result = response.get("result", {})
                    status = result.get("status")
                    
                    if status == "success":
                        predictions = result.get("predictions", {})
                        print(f"âœ… ç–²åŠ³åº¦æ¨ç†æˆåŠŸ")
                        print(f"   ç–²åŠ³åº¦åˆ†æ•°: {predictions.get('fatigue_score'):.2f}")
                        print(f"   é¢„æµ‹ç±»åˆ«: {predictions.get('prediction_class')}")
                        print(f"   æ¨ç†è€—æ—¶: {predictions.get('inference_time_ms', 0):.2f}ms")
                        print(f"   æ€»è€—æ—¶: {latency:.2f}ms")
                        return True
                    else:
                        print(f"âŒ æ¨ç†å¤±è´¥: {result.get('error')}")
                        return False
                elif msg_type == "event":
                    # è·³è¿‡äº‹ä»¶æ¶ˆæ¯
                    continue
                else:
                    print(f"âŒ æœªçŸ¥å“åº”ç±»å‹: {msg_type}")
                    return False
    except Exception as e:
        print(f"âŒ ç–²åŠ³åº¦æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_emotion_inference(uri: str, data_dir: Path):
    """æµ‹è¯•æƒ…ç»ªæ¨ç†"""
    print(f"\n[4/5] æµ‹è¯•æƒ…ç»ªæ¨ç†ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰...")
    
    try:
        # ç”ŸæˆçœŸå®å¯ç”¨çš„è§†é¢‘å’ŒéŸ³é¢‘æ•°æ®
        def create_real_video():
            """åˆ›å»ºçœŸå®çš„è§†é¢‘æ–‡ä»¶å¹¶è¿”å›base64"""
            import tempfile
            import os
            
            # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.avi', delete=False) as tmp:
                tmp_path = tmp.name
            
            try:
                # ä½¿ç”¨ OpenCV åˆ›å»ºçœŸå®çš„è§†é¢‘ï¼ˆæ›´å°çš„å°ºå¯¸å’Œå¸§æ•°ï¼‰
                fourcc = cv2.VideoWriter_fourcc(*'MJPG')
                out = cv2.VideoWriter(tmp_path, fourcc, 10.0, (112, 112))  # æ›´å°çš„åˆ†è¾¨ç‡
                
                # åªå†™å…¥5å¸§ï¼ˆå‡å°‘æ–‡ä»¶å¤§å°ï¼‰
                for _ in range(5):
                    frame = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
                    out.write(frame)
                
                out.release()
                
                # è¯»å–å¹¶ç¼–ç ä¸ºbase64
                with open(tmp_path, 'rb') as f:
                    video_data = f.read()
                
                return base64.b64encode(video_data).decode('utf-8')
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(tmp_path):
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
        
        def create_real_audio():
            """åˆ›å»ºçœŸå®çš„éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›base64"""
            import tempfile
            import os
            import wave
            import struct
            
            # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                tmp_path = tmp.name
            
            try:
                # åˆ›å»ºçœŸå®çš„WAVæ–‡ä»¶ï¼ˆæ›´çŸ­çš„æ—¶é•¿ï¼‰
                sample_rate = 16000
                duration = 1  # åª1ç§’
                num_samples = sample_rate * duration
                
                with wave.open(tmp_path, 'w') as wav_file:
                    wav_file.setnchannels(1)  # å•å£°é“
                    wav_file.setsampwidth(2)  # 16ä½
                    wav_file.setframerate(sample_rate)
                    
                    # ç”Ÿæˆç®€å•çš„æ­£å¼¦æ³¢
                    for i in range(num_samples):
                        value = int(32767.0 * 0.3 * np.sin(2 * np.pi * 440 * i / sample_rate))
                        data = struct.pack('<h', value)
                        wav_file.writeframes(data)
                
                # è¯»å–å¹¶ç¼–ç ä¸ºbase64
                with open(tmp_path, 'rb') as f:
                    audio_data = f.read()
                
                return base64.b64encode(audio_data).decode('utf-8')
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(tmp_path):
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
        
        # å‡†å¤‡3ä¸ªæ¨¡æ‹Ÿæ ·æœ¬
        samples = []
        test_texts = [
            "æˆ‘ä»Šå¤©æ„Ÿè§‰å¾ˆå¥½ï¼Œå¿ƒæƒ…æ„‰å¿«",
            "å·¥ä½œå‹åŠ›æœ‰ç‚¹å¤§ï¼Œéœ€è¦ä¼‘æ¯",
            "è¿™ä¸ªé¡¹ç›®å¾ˆæœ‰æŒ‘æˆ˜æ€§"
        ]
        
        print(f"   æ­£åœ¨ç”ŸæˆçœŸå®è§†é¢‘å’ŒéŸ³é¢‘æ•°æ®ï¼ˆè¾ƒå°å°ºå¯¸ï¼‰...")
        for i in range(3):
            video_b64 = create_real_video()
            audio_b64 = create_real_audio()
            text = test_texts[i]
            
            samples.append({
                "video_b64": video_b64,
                "audio_b64": audio_b64,
                "text": text,
                "question_index": i + 1
            })
            
            print(f"   æ ·æœ¬ {i+1}: è§†é¢‘={len(video_b64)/1024:.1f}KB, éŸ³é¢‘={len(audio_b64)/1024:.1f}KB, æ–‡æœ¬=\"{text}\"")
        
        async with websockets.connect(uri, max_size=100 * 1024 * 1024, open_timeout=60) as ws:
            # å…ˆæ¥æ”¶æ¬¢è¿æ¶ˆæ¯
            welcome_msg = await ws.recv()
            
            request = {
                "type": "model_inference",
                "model_type": "emotion",
                "request_id": "test-emotion",
                "data": {
                    "samples": samples
                },
                "timestamp": time.time()
            }
            
            print(f"   å‘é€æ¨ç†è¯·æ±‚ (å…± {len(samples)} ä¸ªæ ·æœ¬)...")
            start_time = time.time()
            await ws.send(json.dumps(request))
            
            # å¾ªç¯æ¥æ”¶æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°model_inference_result
            while True:
                response = json.loads(await ws.recv())
                msg_type = response.get("type")
                
                if msg_type == "model_inference_result":
                    latency = (time.time() - start_time) * 1000
                    result = response.get("result", {})
                    
                    if result.get("status") == "success":
                        predictions = result.get("predictions", {})
                        print(f"âœ… æƒ…ç»ªæ¨ç†æˆåŠŸ")
                        print(f"   æƒ…ç»ªåˆ†æ•°: {predictions.get('emotion_score', 0):.2f}")
                        print(f"   æ¨ç†è€—æ—¶: {predictions.get('inference_time_ms', 0):.2f}ms")
                        print(f"   æ€»è€—æ—¶: {latency:.2f}ms")
                        return True
                    else:
                        print(f"âŒ æ¨ç†å¤±è´¥: {result.get('error')}")
                        return False
                elif msg_type == "event":
                    # è·³è¿‡äº‹ä»¶æ¶ˆæ¯
                    continue
                else:
                    print(f"âŒ æœªçŸ¥å“åº”ç±»å‹: {msg_type}")
                    return False
                
    except Exception as e:
        print(f"âŒ æƒ…ç»ªæ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_concurrent_inference(uri: str):
    """æµ‹è¯•å¹¶å‘æ¨ç†"""
    print(f"\n[5/5] æµ‹è¯•å¹¶å‘æ¨ç†ï¼ˆç–²åŠ³åº¦æ¨¡å‹ï¼‰...")
    try:
        num_requests = 5
        
        async def single_request(idx: int):
            """å•ä¸ªè¯·æ±‚"""
            # ç”Ÿæˆè¾ƒå°çš„æ¨¡æ‹Ÿæ•°æ®
            num_frames = 30  # å‡å°‘å¸§æ•°
            rgb_frames = []
            for i in range(num_frames):
                img = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
                ok, buffer = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 70])
                if ok:
                    rgb_b64 = base64.b64encode(buffer).decode("ascii")
                    rgb_frames.append(rgb_b64)
            
            depth_frames = []
            for i in range(num_frames):
                depth = np.random.randint(0, 255, (112, 112), dtype=np.uint8)
                ok, buffer = cv2.imencode(".png", depth)
                if ok:
                    depth_b64 = base64.b64encode(buffer).decode("ascii")
                    depth_frames.append(depth_b64)
            
            eyetrack_samples = [list(np.random.rand(8)) for _ in range(num_frames * 5)]
            
            async with websockets.connect(uri, max_size=100 * 1024 * 1024, open_timeout=30) as ws:
                # å…ˆæ¥æ”¶æ¬¢è¿æ¶ˆæ¯
                welcome_msg = await ws.recv()
                
                request = {
                    "type": "model_inference",
                    "model_type": "fatigue",
                    "request_id": f"test-concurrent-{idx}",
                    "data": {
                        "rgb_frames": rgb_frames,
                        "depth_frames": depth_frames,
                        "eyetrack_samples": eyetrack_samples,
                        "elapsed_time": 5.0 + idx * 0.5
                    },
                    "timestamp": time.time()
                }
                
                start_time = time.time()
                await ws.send(json.dumps(request))
                
                # å¾ªç¯æ¥æ”¶æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°model_inference_result
                while True:
                    response = json.loads(await ws.recv())
                    msg_type = response.get("type")
                    
                    if msg_type == "model_inference_result":
                        latency = (time.time() - start_time) * 1000
                        result = response.get("result", {})
                        
                        if result.get("status") == "success":
                            predictions = result.get("predictions", {})
                            fatigue_score = predictions.get("fatigue_score", 0)
                            return (idx, latency, fatigue_score, True)
                        else:
                            return (idx, latency, 0, False)
                    elif msg_type == "event":
                        # è·³è¿‡äº‹ä»¶æ¶ˆæ¯
                        continue
                    else:
                        return (idx, latency, 0, False)
        
        print(f"   å‘é€ {num_requests} ä¸ªå¹¶å‘è¯·æ±‚...")
        tasks = [single_request(i) for i in range(num_requests)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        successful = []
        failed = []
        for result in results:
            if isinstance(result, Exception):
                failed.append(result)
            elif result[3]:  # success
                successful.append(result)
            else:
                failed.append(result)
        
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ")
        print(f"   æˆåŠŸ: {len(successful)}/{num_requests}")
        print(f"   å¤±è´¥: {len(failed)}/{num_requests}")
        
        if successful:
            latencies = [r[1] for r in successful]
            scores = [r[2] for r in successful]
            print(f"   å¹³å‡å»¶è¿Ÿ: {sum(latencies)/len(latencies):.2f}ms")
            print(f"   æœ€å°å»¶è¿Ÿ: {min(latencies):.2f}ms")
            print(f"   æœ€å¤§å»¶è¿Ÿ: {max(latencies):.2f}ms")
            print(f"   å¹³å‡ç–²åŠ³åº¦: {sum(scores)/len(scores):.2f}")
        
        return len(successful) > 0
        
    except Exception as e:
        print(f"âŒ å¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 70)
    print("ç»Ÿä¸€æ¨ç†åç«¯é›†æˆæµ‹è¯•ï¼ˆé›†æˆæ¨¡å¼ï¼‰")
    print("=" * 70)
    
    uri = "ws://127.0.0.1:8765"
    print(f"\næµ‹è¯•ç›®æ ‡: {uri}")
    print("è¯·ç¡®ä¿ä¸»åç«¯å·²å¯åŠ¨ (python -m src.main)\n")
    
    results = []
    
    # è¿è¡Œæµ‹è¯•ï¼ˆä¸å†éœ€è¦çœŸå®æ•°æ®ç›®å½•ï¼‰
    results.append(("åç«¯è¿æ¥", await test_backend_connection(uri)))
    results.append(("æ¨¡å‹çŠ¶æ€", await test_model_status(uri)))
    results.append(("ç–²åŠ³åº¦æ¨ç†", await test_fatigue_inference(uri)))
    results.append(("æƒ…ç»ªæ¨ç†", await test_emotion_inference(uri, None)))  # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œä¸éœ€è¦è·¯å¾„
    results.append(("å¹¶å‘æ¨ç†", await test_concurrent_inference(uri)))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {name}")
    
    print(f"\né€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
